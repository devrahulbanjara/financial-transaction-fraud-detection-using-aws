{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c986e020",
   "metadata": {},
   "source": [
    "# Restoring Your SageMaker Session: Reloading Endpoints and Tuners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35500d72",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "When working with long-running processes in Jupyter Notebooks, such as machine learning model training and deployment, a kernel restart can lead to the loss of all in-memory variables. However, resources created in AWS SageMaker, like endpoints and completed training jobs, persist independently of your notebook session.\n",
    "\n",
    "This supplementary notebook provides the necessary code snippets to reconnect to your existing SageMaker endpoints and re-instantiate your hyperparameter tuner object. By doing this, you can resume your workflow, perform further evaluations, or proceed with new tasks without needing to rerun the entire original notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523651ab",
   "metadata": {},
   "source": [
    "**Prerequisite:** You must have already run the main `train_tune_deploy_register.ipynb` notebook to create the SageMaker resources (endpoints and the hyperparameter tuning job) that you intend to reload.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa4ead1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c5e4bb",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1.  [Setup and Essential Imports](#setup-supplement)\n",
    "2.  [Reloading SageMaker Endpoints](#reload-endpoints)\n",
    "    1.  [Define Endpoint Names](#define-endpoints)\n",
    "    2.  [Create Predictor Objects](#create-predictors)\n",
    "3.  [Reloading the Hyperparameter Tuner Object](#reload-tuner)\n",
    "    1.  [List Completed Tuning Jobs](#list-jobs)\n",
    "    2.  [Attach to the Specific Tuning Job](#attach-tuner)\n",
    "    3.  [Access the Best Estimator](#access-estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a226473",
   "metadata": {},
   "source": [
    "## 1. Setup and Essential Imports\n",
    "\n",
    "To begin, we need to import the core libraries required to interact with SageMaker and AWS. These are the `sagemaker`, `boto3`, and specific classes like `Predictor` and `HyperparameterTuner`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73e10f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "# Establish a SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "# Initialize the boto3 client for SageMaker\n",
    "sm_client = boto3.client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f31eb0f",
   "metadata": {},
   "source": [
    "## 2. Reloading SageMaker Endpoints\n",
    "\n",
    "Even after a kernel restart, your deployed SageMaker endpoints are still active and ready to serve predictions. To use them, we simply need to create a `Predictor` object and point it to the existing endpoint name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803ef20e",
   "metadata": {},
   "source": [
    "### 2.1. Define Your Endpoint Names\n",
    "\n",
    "First, you must provide the names of the endpoints you created in your previous session.\n",
    "\n",
    "**Action Required:** Replace the placeholder strings below with the actual names of your deployed endpoints. You can find these names in the output of the original notebook or in the SageMaker console under \"Inference\" -> \"Endpoints\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eff299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with the name of your endpoint from the initial model training\n",
    "before_tuning_endpoint_name = \"fraud-detection-2025-08-06-09-38-15-060\"\n",
    "\n",
    "# Replace with the name of your endpoint from the hyperparameter-tuned model\n",
    "after_tuning_endpoint_name = \"sagemaker-xgboost-2025-08-06-10-16-24-980\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc849ce",
   "metadata": {},
   "source": [
    "### 2.2. Create Predictor Objects\n",
    "\n",
    "Now, we instantiate `Predictor` objects for each endpoint. This re-establishes the connection from our notebook to the live endpoints. We also need to re-apply the `CSVSerializer`, as this setting is part of the client-side object and was lost when the kernel restarted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd0cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor = Predictor(\n",
    "    endpoint_name=before_tuning_endpoint_name,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0d973d",
   "metadata": {},
   "source": [
    "Create a Predictor object for the tuned model's endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc2e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_xgb_predictor = Predictor(\n",
    "    endpoint_name=after_tuning_endpoint_name,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdc2b02",
   "metadata": {},
   "source": [
    "Re-apply the serializer for sending data in CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fd178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.serializer = CSVSerializer()\n",
    "tuned_xgb_predictor.serializer = CSVSerializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0deb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Successfully reconnected to non-tuned endpoint: {xgb_predictor.endpoint_name}\")\n",
    "print(f\"Successfully reconnected to tuned endpoint: {tuned_xgb_predictor.endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4f963d",
   "metadata": {},
   "source": [
    "You can now use `xgb_predictor.predict()` and `tuned_xgb_predictor.predict()` as you did in the original notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71271ea5",
   "metadata": {},
   "source": [
    "## 3. Reloading the Hyperparameter Tuner Object\n",
    "\n",
    "The results and configuration of a completed hyperparameter tuning job are stored persistently in SageMaker. We can retrieve this information to recreate the tuner object in our notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a30b0a",
   "metadata": {},
   "source": [
    "### 3.1. List Completed Tuning Jobs to Find the Name\n",
    "\n",
    "If you don't remember the exact name of your tuning job, you can list the most recent completed jobs using the `boto3` client. This helps you identify the correct job to attach to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b3ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the 10 most recent completed hyperparameter tuning jobs\n",
    "response = sm_client.list_hyper_parameter_tuning_jobs(\n",
    "    SortBy='CreationTime',\n",
    "    SortOrder='Descending',\n",
    "    StatusEquals='Completed',\n",
    "    MaxResults=10\n",
    ")\n",
    "\n",
    "print(\"Recent Completed Tuning Jobs:\")\n",
    "for job in response['HyperParameterTuningJobSummaries']:\n",
    "    print(f\"- {job['HyperParameterTuningJobName']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721b2e6f",
   "metadata": {},
   "source": [
    "### 3.2. Attach to the Specific Tuning Job\n",
    "\n",
    "Once you have identified the correct tuning job name from the list above, assign it to the `tuning_job_name` variable. Then, use the `HyperparameterTuner.attach()` class method to recreate the tuner object.\n",
    "\n",
    "**Action Required:** Copy the name of your tuning job from the output above and paste it into the `tuning_job_name` variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b74df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with the name of your hyperparameter tuning job\n",
    "tuning_job_name = \"sagemaker-xgboost-250806-1008\"\n",
    "\n",
    "# Attach to the existing tuning job to recreate the tuner object\n",
    "tuner = HyperparameterTuner.attach(\n",
    "    tuning_job_name=tuning_job_name,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "print(f\"Successfully attached to tuner job: {tuner.latest_tuning_job.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07137594",
   "metadata": {},
   "source": [
    "### 3.3. Access the Best Estimator\n",
    "\n",
    "With the `tuner` object re-instantiated, you can now access all of its properties and methods as if you had just completed the tuning job. For example, you can easily retrieve the best-performing estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213293d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best estimator from the tuning job\n",
    "best_estimator = tuner.best_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7bbf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Successfully retrieved the best estimator from the tuner.\")\n",
    "print(f\"Best training job name: {tuner.best_training_job()}\")\n",
    "print(f\"Model artifacts for the best estimator are at: {best_estimator.model_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578d401b",
   "metadata": {},
   "source": [
    "You can now use the `best_estimator` object to, for instance, deploy the model, register it, or analyze its hyperparameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
